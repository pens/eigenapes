{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "DATA_DIR = 'data/' # Intermediates\n",
    "IMAGE_DIR = DATA_DIR + 'apes/'\n",
    "OUTPUT_DIR = 'output/' # Ready to use / upload\n",
    "\n",
    "os.makedirs(f'{OUTPUT_DIR}blog', exist_ok=True)\n",
    "os.makedirs(f'{OUTPUT_DIR}nft/opensea', exist_ok=True)\n",
    "os.makedirs(f'{OUTPUT_DIR}nft/eigenapes', exist_ok=True)\n",
    "\n",
    "mpl.rc('image', cmap='gray')\n",
    "mpl.rc('figure', dpi=200, figsize=[8, 4])\n",
    "mpl.rc('savefig', facecolor='w')\n",
    "\n",
    "IMSHOW_PARAMS = {\n",
    "    'norm': matplotlib.colors.Normalize(0, 255)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading images...')\n",
    "\n",
    "filenames = os.listdir(IMAGE_DIR)\n",
    "count = len(filenames)\n",
    "\n",
    "im = Image.open(f'{IMAGE_DIR}{filenames[0]}')\n",
    "\n",
    "w, h = im.size\n",
    "X = np.ndarray((h * w, count), dtype=np.float32)\n",
    "\n",
    "for i in range(count):\n",
    "    im = Image.open(f'{IMAGE_DIR}{filenames[i]}').convert('L')\n",
    "    X[:, i] = im.getdata()\n",
    "\n",
    "print(\"Subtracting mean...\")\n",
    "\n",
    "X_mean = np.mean(X, 1)\n",
    "\n",
    "for i in range(count):\n",
    "    X[:, i] -= X_mean\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare unnormalized matrix with normalized\n",
    "# Mean is subtracted, but this is just to check fp math\n",
    "#\n",
    "# Result: don't need to normalize\n",
    "\n",
    "for normalize in [False, True]:\n",
    "    X_small = X[:, :100].copy()\n",
    "    if normalize:\n",
    "        X_small /= 255\n",
    "\n",
    "    U, s, Vh = np.linalg.svd(X_small, full_matrices=False)\n",
    "    X_recon = U.dot(np.diag(s)).dot(Vh)\n",
    "    if normalize:\n",
    "        X_recon *= 255\n",
    "    \n",
    "    norm = np.mean(np.linalg.norm(X_recon - X[:, :100], None, 0))\n",
    "\n",
    "    print(('Normalized' if normalize else 'Unnormalized') + f': {norm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark different SVD methods\n",
    "# Roughly sorted by expected duration, descending\n",
    "\n",
    "k = 100\n",
    "X_small = X[:, :2*k].copy()\n",
    "\n",
    "trials = {\n",
    "    'Truncated SVD  (numpy)    ': lambda: np.linalg.svd(X_small, full_matrices=False),\n",
    "    'Sparse SVD     (scipy)    ': lambda: scipy.sparse.linalg.svds(X_small, k),\n",
    "    'Randomized SVD (sklearn)  ': lambda: randomized_svd(X_small, k, random_state=0),\n",
    "}\n",
    "\n",
    "for name, fn in trials.items():\n",
    "    start = time.perf_counter()\n",
    "    fn()\n",
    "    print(f'{name}: {time.perf_counter() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SVD on whole dataset\n",
    "\n",
    "k = 800\n",
    "U, s, Vh = randomized_svd(X, k, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction of first image\n",
    "#\n",
    "# Result: 400 is very good\n",
    "\n",
    "fig = plt.figure()\n",
    "rows = 2\n",
    "cols = 3\n",
    "grid = ImageGrid(fig, 111, (rows, cols))\n",
    "\n",
    "ks = [300, 320, 350, 361, 400]\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        if r == 0 and c == 0:\n",
    "            grid[r * cols + c].imshow((X_mean + X[:, 0]).reshape(h, w), **IMSHOW_PARAMS)\n",
    "        else:\n",
    "            i = ks[r * cols + c - 1]\n",
    "            Xr = U[:, :i].dot(np.diag(s[:i])).dot(Vh[:i, 0])\n",
    "            grid[r * cols + c].imshow((X_mean + Xr).reshape(h, w), **IMSHOW_PARAMS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multiple images at same k\n",
    "#\n",
    "# Result: 400 will be fine, although uncertain for faces with rare features\n",
    "\n",
    "fig = plt.figure()\n",
    "rows = 5\n",
    "cols = 5\n",
    "grid = ImageGrid(fig, 111, (rows, cols))\n",
    "num_k = 400\n",
    "\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        i = r * cols + c\n",
    "        Xr = U[:, :num_k].dot(np.diag(s[:num_k])).dot(Vh[:num_k, i])\n",
    "        grid[i].imshow((X_mean + Xr).reshape(h, w), **IMSHOW_PARAMS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reconstructions of an image using very few modes\n",
    "\n",
    "fig = plt.figure()\n",
    "rows = 1\n",
    "cols = 5\n",
    "grid = ImageGrid(fig, 111, (rows, cols))\n",
    "\n",
    "for i in range(cols):\n",
    "    grid[i].imshow((U[:, :i].dot(np.diag(s[:i])).dot(Vh[:i, 0]) + X_mean).reshape(h, w), **IMSHOW_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert eigenfaces to RGB\n",
    "# Red is positive and blue negative (should match mpl's bwr)\n",
    "\n",
    "num_k = 400\n",
    "eigenfaces_rgb = np.zeros((h, w, 3, num_k), dtype=np.uint8)\n",
    "scales = np.zeros(k)\n",
    "\n",
    "for i in range(num_k):\n",
    "    eigenface = U[:, i].reshape(h, w).copy()\n",
    "\n",
    "    # Normalize to [-1, 1]\n",
    "    scales[i] = np.max(np.abs(eigenface))\n",
    "    eigenface /= scales[i]\n",
    "\n",
    "    eigenfaces_rgb[..., 0, i] = 255 - eigenface.clip(max=0) * -255\n",
    "    eigenfaces_rgb[..., 1, i] = 255 - np.abs(eigenface) * 255\n",
    "    eigenfaces_rgb[..., 2, i] = 255 - eigenface.clip(min=0) * 255\n",
    "\n",
    "plt.imshow(eigenfaces_rgb[..., 4], **IMSHOW_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images and metadata for NFT\n",
    "\n",
    "print('Saving images...')\n",
    "\n",
    "attributes = {}\n",
    "\n",
    "for i in range(num_k):\n",
    "    attributes[i] = {\n",
    "        'scale_factor': float(scales[i]),\n",
    "        'singular_value': float(s[i])\n",
    "    }\n",
    "\n",
    "    im = Image.fromarray(eigenfaces_rgb[..., i])\n",
    "    im.save(f'{OUTPUT_DIR}nft/eigenapes/{i}.png')\n",
    "\n",
    "print('Done. Saving attribute metadata...')\n",
    "\n",
    "with open(f'{DATA_DIR}eigenape_attributes.json', 'w') as f:\n",
    "    json.dump(attributes, f)\n",
    "\n",
    "print('Metadata saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images for blog, OpenSea\n",
    "\n",
    "def make_grid(rows, cols):\n",
    "    grid = np.zeros((rows * h, cols * w, 3), dtype=np.uint8)\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols): \n",
    "            i = r * cols + c\n",
    "            grid[r*h:(r+1)*h, c*w:(c+1)*w, :] = eigenfaces_rgb[..., i] \n",
    "    \n",
    "    return grid\n",
    "\n",
    "eigenfaces_main = make_grid(2, 3)\n",
    "eigenfaces_banner = make_grid(4, 14)\n",
    "eigenfaces_all = make_grid(20, 20)[::4, ::4, ...]\n",
    "\n",
    "f, ax = plt.subplots(3, 1)\n",
    "ax[0].imshow(eigenfaces_main)\n",
    "ax[1].imshow(eigenfaces_banner)\n",
    "ax[2].imshow(eigenfaces_all)\n",
    "\n",
    "# For blog\n",
    "im = Image.fromarray(eigenfaces_main)\n",
    "im.save(f'{OUTPUT_DIR}blog/main_eigenfaces.png')\n",
    "\n",
    "im = Image.fromarray(eigenfaces_all)\n",
    "im.save(f'{OUTPUT_DIR}blog/all_eigenfaces.jpg')\n",
    "\n",
    "# For OpenSea\n",
    "im = Image.fromarray(eigenfaces_main)\n",
    "im = im.resize((600, 400))\n",
    "im.save(f'{OUTPUT_DIR}nft/opensea/highlight.png')\n",
    "\n",
    "im = Image.fromarray(eigenfaces_banner)\n",
    "im.resize((1400, 400))\n",
    "im.save(f'{OUTPUT_DIR}nft/opensea/banner.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular value graphs for blog\n",
    "\n",
    "energy = np.cumsum(s) / np.sum(s)\n",
    "e90 = np.searchsorted(energy, .9)\n",
    "e95 = np.searchsorted(energy, .95)\n",
    "e99 = np.searchsorted(energy, .99)\n",
    "\n",
    "f, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].set_title('Singular Values')\n",
    "ax[0].set_xlabel('$i$')\n",
    "ax[0].set_ylabel('$\\sigma_i$')\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].plot(s)\n",
    "\n",
    "ax[1].set_title('Cumulative Energy')\n",
    "ax[1].set_xlabel('$i$')\n",
    "ax[1].set_ylabel('$\\sum_{j=1}^{i} \\sigma_j / \\sum_{j=1}^{' + f'{k}' + '} \\sigma_j$')\n",
    "ax[1].plot(energy)\n",
    "ax[1].axvline(e90, c='r')\n",
    "ax[1].text(e90 + 10, 0.1, '90%', rotation=90)\n",
    "ax[1].axvline(e95, c='g')\n",
    "ax[1].text(e95 + 10, 0.1, '95%', rotation=90)\n",
    "ax[1].axvline(e99, c='b')\n",
    "ax[1].text(e99 + 10, 0.1, '99%', rotation=90)\n",
    "\n",
    "f.tight_layout()\n",
    "f.savefig(f'{OUTPUT_DIR}blog/sing_values.png')\n",
    "\n",
    "print(f'Cumulative energy at k: {energy[num_k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph showing error v k, up to 1000. For blog.\n",
    "# Warning: slow and memory intensive with high num_tests\n",
    "\n",
    "num_tests = 25\n",
    "idxs = np.random.randint(0, X.shape[1], num_tests)\n",
    "X_idxs = X[:, idxs]\n",
    "Vh_idxs = Vh[:, idxs]\n",
    "recons = np.zeros((X.shape[0], num_tests))\n",
    "norms = np.ndarray((num_tests, k))\n",
    "\n",
    "for i in range(k):\n",
    "    recons += np.outer(U[:, i], Vh_idxs[i, :]) * s[i]\n",
    "    norms[:, i] = np.linalg.norm(recons - X_idxs, None, 0)\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "ax.plot(norms.T)\n",
    "ax.set_title('Reconstruction Error vs $i$ Greatest $\\sigma_i$, ' + f'{num_tests} Columns')\n",
    "ax.set_xlabel('$i$')\n",
    "ax.set_ylabel('$||X-X_i||_2$')\n",
    "f.savefig(f'{OUTPUT_DIR}blog/norms.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
